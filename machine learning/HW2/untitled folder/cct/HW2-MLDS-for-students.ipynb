{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hello and welcome to decision trees!\n",
    "Decision trees are often pretty effect learning algorithms, and certainly serve as an interesting technical exercise in data preprocessing and recursion. This notebook will walk you through some of the basic notions of how the implementation should be executed, and also give you a chance to write some of your own code.\n",
    "\n",
    "Suggested reading before you start: https://www.cs.princeton.edu/courses/archive/spring07/cos424/papers/mitchell-dectrees.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout the notebook you'll see TODO tags in the comments. This is where you should insert your own code to make the functions work! If you get stuck, we encourage you to come to office hours. You can also try to look at APIs and documentation online to try to get a sense how certain methods work. If you take inspiration from any source online other than official documentation, please be sure to cite the resource! Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.io\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using decision trees to classify if a banknote is fradulent (class 1) or not fradulent (class 0). Download data from https://archive.ics.uci.edu/ml/datasets/banknote+authentication#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO YOUR CODE HERE\n",
    "def import_data(split = 0.8, shuffle=False):\n",
    "    \"\"\"Read in the data, split it by split percentage into train and test data, \n",
    "    and return X_train, y_train, X_test, y_test as numpy arrays\"\"\"\n",
    "    # TODO\n",
    "    df = pd.read_csv('./data_banknote_authentication.txt',header = None, \n",
    "                names = ['vairance','skewness','curtosis','entropy','class'])\n",
    "    \n",
    "    #shuffle the data\n",
    "    df_shuffle = df.sample(frac=1)\n",
    "    \n",
    "    #split the data to get train and test data\n",
    "    train = df_shuffle[:round(split*len(df))]\n",
    "    test = df_shuffle[round(split*len(df)):]\n",
    "    \n",
    "    X_train = np.array(train.iloc[:,:-1])\n",
    "    y_train = np.array(train.iloc[:,-1])\n",
    "    X_test = np.array(test.iloc[:,:-1])\n",
    "    y_test = np.array(test.iloc[:,-1])\n",
    "    \n",
    "    print(\"data imported\")\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \"\"\"Each node of our decision tree will hold values such as left and right children, \n",
    "    the data and labels being split on, the threshold value & index in the dataframe for a particular feature,\n",
    "    and the uncertainty measure for this node\"\"\"\n",
    "    def __init__(self, data, labels, depth):\n",
    "        \"\"\"\n",
    "        data: X data\n",
    "        labels: y data\n",
    "        depth: depth of tree\n",
    "        \"\"\"\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.depth = depth\n",
    "\n",
    "        self.threshold = None # threshold value\n",
    "        self.threshold_index = None # threshold index\n",
    "        self.feature = None # feature as a NUMBER (column number)\n",
    "        self.label = None # y label\n",
    "        self.uncertainty = None # uncertainty value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    def __init__(self, K=5, verbose=False):\n",
    "        \"\"\"\n",
    "        K: number of features to split on \n",
    "        \"\"\"\n",
    "        self.root = None\n",
    "        self.K = K\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def buildTree(self, data, labels, metric=\"entropy\"):\n",
    "        \"\"\"Builds tree for training on data. Recursively called _buildTree\"\"\"\n",
    "        self.root = Node(data, labels, 0)\n",
    "        if self.verbose:\n",
    "            print(\"Root node shape: \", data.shape, labels.shape)\n",
    "        self._buildTree(self.root,metric)\n",
    "    \n",
    "    def _buildTree(self, node):\n",
    "             \n",
    "        # get uncertainty measure and feature threshold\n",
    "        node.uncertainty = self.get_uncertainty(node.labels)\n",
    "        self.get_feature_threshold(node)\n",
    "            \n",
    "        index = node.data[:, node.feature].argsort()  # sort feature for return\n",
    "        node.data = node.data[index]\n",
    "        node.labels = node.labels[index]\n",
    "        \n",
    "        # check label distribution.\n",
    "        label_distribution = np.bincount(node.labels)\n",
    "        majority_label = node.labels[0] if len(label_distribution) == 1 else np.argmax(label_distribution)\n",
    "            \n",
    "        if self.verbose:\n",
    "            print(\"Node uncertainty: %f\" % node.uncertainty)\n",
    "    \n",
    "        # Split left and right if threshold is not the min or max of the feature or every point has the\n",
    "        # same label.\n",
    "        if node.threshold_index == 0 or node.threshold_index == node.data.shape[0] or \\\n",
    "            len(label_distribution) == 1:\n",
    "            node.label = majority_label\n",
    "        else:\n",
    "            node.left = Node(node.data[:node.threshold_index], node.labels[:node.threshold_index], node.depth + 1)\n",
    "            node.right = Node(node.data[node.threshold_index:], node.labels[node.threshold_index:], node.depth + 1)            \n",
    "            node.data = None\n",
    "            node.labels = None\n",
    "                        \n",
    "            # If in last layer of tree, assign predictions\n",
    "            if node.depth == self.K:\n",
    "                if len(node.left.labels) == 0:\n",
    "                    node.right.label = np.argmax(np.bincount(node.right.labels))\n",
    "                    node.left.label = 1 - node.right.label\n",
    "                elif len(node.right.labels) == 0:\n",
    "                    node.left.label = np.argmax(np.bincount(node.left.labels))\n",
    "                    node.right.label = 1 - node.left.label\n",
    "                else:\n",
    "                    node.left.label = np.argmax(np.bincount(node.left.labels))\n",
    "                    node.right.label = np.argmax(np.bincount(node.right.labels))\n",
    "                return\n",
    "\n",
    "            else: # Otherwise continue training the tree by calling _buildTree\n",
    "                self._buildTree(node.left)\n",
    "                self._buildTree(node.right)\n",
    "\n",
    "    def predict(self, data_pt):\n",
    "        return self._predict(data_pt, self.root)\n",
    "\n",
    "    def _predict(self, data_pt, node):\n",
    "        feature = node.feature\n",
    "        threshold = node.threshold\n",
    "        if node.label is not None:\n",
    "            return node.label\n",
    "        elif data_pt[node.feature] < node.threshold:\n",
    "            return self._predict(data_pt, node.left)\n",
    "        elif data_pt[node.feature] >= node.threshold:\n",
    "            return self._predict(data_pt, node.right)\n",
    "\n",
    "    def get_feature_threshold(self, node,metric=\"entropy\"):\n",
    "        \"\"\" TODO Find the feature that gives the largest information gain. Update node.threshold, \n",
    "        node.threshold_index, and node.feature (a number representing the feature. e.g. 2nd column feature would be 1)\n",
    "        Make sure to sort the columns of data before you try to find the threshold index (look at numpy argsort) and set the values\n",
    "        for node.threshold, node.threshold_index, and node.feature\n",
    "        return: None\n",
    "        \"\"\"\n",
    "        node.threshold = 0\n",
    "        node.threshold_index = 0\n",
    "        node.feature = 0\n",
    "        # TODO YOUR CODE HERE\n",
    "        info_gain = []\n",
    "        for col in range(node.data.shape[1]):\n",
    "            node.feature = col\n",
    "            info_gain.append([self.getInfoGain(node,i,metric) for i in range(node.labels.shape[0])])\n",
    "        \n",
    "        info_gain = np.array(info_gain)\n",
    "        max_index = np.unravel_index(info_gain.argmax(), info_gain.shape)\n",
    "        node.feature = max_index[0]\n",
    "        node.threshold_index = max_index[1]\n",
    "        node.threshold = sorted(node.data[:,node.feature])[node.threshold_index]\n",
    "\n",
    "    def getInfoGain(self, node, split_index,metric=\"entropy\"):\n",
    "        \"\"\"\n",
    "        TODO Get information gain using the variables in the parameters, \\\n",
    "        split_index: index in the feature column that you are splitting the classes on\n",
    "        return: information gain (float)\n",
    "        \"\"\"\n",
    "        # TODO YOUR CODE HERE\n",
    "        index = node.data[:, node.feature].argsort()\n",
    "        labels = node.labels[index]\n",
    "        return(self.get_uncertainty(labels,metric) -\n",
    "               split_index/labels.shape[0]*self.get_uncertainty(labels[:split_index],metric) - \n",
    "               (labels.shape[0]-split_index)/labels.shape[0]*self.get_uncertainty(labels[split_index:],metric))\n",
    "\n",
    "\n",
    "    def get_uncertainty(self, labels, metric=\"entropy\"):\n",
    "        \"\"\"\n",
    "        TODO Get uncertainty. Implement entropy AND gini index metrics. \n",
    "        np.bincount(labels) and labels.shape might be useful here\n",
    "        return: uncertainty (float)\n",
    "        \"\"\"\n",
    "        \n",
    "        if labels.shape[0] == 0:\n",
    "            return 1\n",
    "        for y, n_k in zip(np.unique(labels),np.bincount(labels)):\n",
    "            p[y] = n_k/labels.shape[0] \n",
    "        if 0 in p.values(): return 0\n",
    "        if metric == 'entropy':\n",
    "            return(sum([-p_k*np.log(p_k) for p_k in p.values()]))   \n",
    "        if metric == 'gini':\n",
    "            return(sum([p_k*(1-p_k) for p_k in p.values()]))\n",
    "\n",
    "    def evaluation(self):\n",
    "        feat_freq = {}\n",
    "        feat_freq = self._evaluation(self.root,feat_freq)\n",
    "        print(\"The feature frequency of depth {} is {}.\".format(self.K,feat_freq))\n",
    "    \n",
    "    def _evaluation(self,node,feat_freq):\n",
    "        if node is not None:\n",
    "            if node.label is None:\n",
    "                if node.feature in feat_freq.keys(): feat_freq[node.feature] += 1\n",
    "                else: feat_freq[node.feature] = 1\n",
    "            feat_freq = self._evaluation(node.left,feat_freq)\n",
    "            feat_freq = self._evaluation(node.right,feat_freq)\n",
    "        return feat_freq\n",
    "    \n",
    "    def printTree(self):\n",
    "        \"\"\"Prints the tree including threshold value and feature name\"\"\"\n",
    "        self._printTree(self.root)\n",
    "\n",
    "    def _printTree(self, node):\n",
    "        if node is not None:\n",
    "            if node.label is None:\n",
    "                print(\"\\t\" * node.depth, \"(%d, %d)\" % (node.threshold, node.feature))\n",
    "            else:\n",
    "                print(\"\\t\" * node.depth, node.label)\n",
    "            self._printTree(node.left)\n",
    "            self._printTree(node.right)\n",
    "\n",
    "    def homework_evaluate(self, X_train, labels, X_test, y_test):\n",
    "        n = X_train.shape[0]\n",
    "\n",
    "        count = 0\n",
    "        for i in range(n):\n",
    "            if self.predict(X_train[i]) == labels[i]:\n",
    "                count += 1\n",
    "\n",
    "        print(\"The decision tree is %d percent accurate on %d training data\" % ((count / n) * 100, n))\n",
    "\n",
    "        n = X_test.shape[0]\n",
    "\n",
    "        count = 0\n",
    "        for i in range(n):\n",
    "            if self.predict(X_test[i]) == y_test[i]:\n",
    "                count += 1\n",
    "\n",
    "        print(\"The decision tree is %d percent accurate on %d test data\" % ((count / n) * 100, n))\n",
    "\n",
    "        return count / n\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the tree\n",
    "Try different values of K (depth of tree a.k.a. number of features the tree will split on) and compare the performance. Which feature gives the largest information gain? Which feature is the least useful for the decision tree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data imported\n",
      "The decision tree is 98 percent accurate on 1098 training data\n",
      "The decision tree is 95 percent accurate on 274 test data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9562043795620438"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = import_data(split=0.8)\n",
    "\n",
    "tree = DecisionTree(K=3, verbose=False)\n",
    "tree.buildTree(X_train, y_train)\n",
    "\n",
    "tree.homework_evaluate(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Entropy as metric:\n",
      "K=3:\n",
      "The decision tree is 98 percent accurate on 1098 training data\n",
      "The decision tree is 95 percent accurate on 274 test data\n",
      "The feature frequency of depth 3 is {0: 5, 1: 3, 2: 3, 3: 1}.\n",
      "K=4:\n",
      "The decision tree is 99 percent accurate on 1098 training data\n",
      "The decision tree is 98 percent accurate on 274 test data\n",
      "The feature frequency of depth 4 is {0: 6, 1: 3, 2: 5, 3: 1}.\n",
      "K=5:\n",
      "The decision tree is 99 percent accurate on 1098 training data\n",
      "The decision tree is 98 percent accurate on 274 test data\n",
      "The feature frequency of depth 5 is {0: 6, 1: 4, 2: 5, 3: 1}.\n",
      "K=6:\n",
      "The decision tree is 99 percent accurate on 1098 training data\n",
      "The decision tree is 98 percent accurate on 274 test data\n",
      "The feature frequency of depth 6 is {0: 6, 1: 4, 2: 6, 3: 1}.\n",
      "K=7:\n",
      "The decision tree is 99 percent accurate on 1098 training data\n",
      "The decision tree is 98 percent accurate on 274 test data\n",
      "The feature frequency of depth 7 is {0: 6, 1: 4, 2: 6, 3: 1}.\n"
     ]
    }
   ],
   "source": [
    "tree_entropy = {}\n",
    "print('Use Entropy as metric:')\n",
    "for k in range(3,8):\n",
    "    tree_entropy[k] = DecisionTree(K=k, verbose=False)\n",
    "    tree_entropy[k].buildTree(X_train, y_train)\n",
    "    print('K={}:'.format(k))\n",
    "    \n",
    "    tree_entropy[k].homework_evaluate(X_train, y_train, X_test, y_test)\n",
    "    tree_entropy[k].evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Gini as metric:\n",
      "K=3:\n",
      "The decision tree is 98 percent accurate on 1098 training data\n",
      "The decision tree is 95 percent accurate on 274 test data\n",
      "The feature frequency of depth 3 is {0: 5, 1: 3, 2: 3, 3: 1}.\n",
      "K=4:\n",
      "The decision tree is 99 percent accurate on 1098 training data\n",
      "The decision tree is 98 percent accurate on 274 test data\n",
      "The feature frequency of depth 4 is {0: 6, 1: 3, 2: 5, 3: 1}.\n",
      "K=5:\n",
      "The decision tree is 99 percent accurate on 1098 training data\n",
      "The decision tree is 98 percent accurate on 274 test data\n",
      "The feature frequency of depth 5 is {0: 6, 1: 4, 2: 5, 3: 1}.\n",
      "K=6:\n",
      "The decision tree is 99 percent accurate on 1098 training data\n",
      "The decision tree is 98 percent accurate on 274 test data\n",
      "The feature frequency of depth 6 is {0: 6, 1: 4, 2: 6, 3: 1}.\n",
      "K=7:\n",
      "The decision tree is 99 percent accurate on 1098 training data\n",
      "The decision tree is 98 percent accurate on 274 test data\n",
      "The feature frequency of depth 7 is {0: 6, 1: 4, 2: 6, 3: 1}.\n"
     ]
    }
   ],
   "source": [
    "tree_gini = {}\n",
    "print('Use Gini as metric:')\n",
    "for k in range(3,8):\n",
    "    tree_gini[k] = DecisionTree(K=k, verbose=False)\n",
    "    tree_gini[k].buildTree(X_train, y_train, metric='gini')\n",
    "    print('K={}:'.format(k))\n",
    "    tree_gini[k].homework_evaluate(X_train, y_train, X_test, y_test)\n",
    "    tree_gini[k].evaluation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that adding depth of the trees can improve the accuracy of the models. The accuracy of the models using Gini is close to that using Entropy. Because the two metrics have similar trends, the results of the two metrics are similar.\n",
    "What's more, from the feature frequecy of the nodes we can see that the most useful features are 0 and 1. The least useful feature is 3.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ————————————————————————————————"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional Decision Tree Exercise\n",
    "This section is designed to give you some exposure to typical preprocessing and allow you to run your decision tree code on another example. \n",
    "\n",
    "All of the preprocessing has been done for you — there's nothing you need to fill in, but it may be worthwhile to tinker with some of the pieces to make \n",
    "sure you understand how everything fits together. \n",
    "\n",
    "Otherwise, if your decision tree code works on the bank notes example, you should be able to run through this straight away. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Data Preprocessing\n",
    "To start, you'll need to download the data files from https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer/.\n",
    "The file `breast-cancer.data` contains the actual data you'll need and the file `breast-cancer.names` gives some information about the researchers and the data types (it's probably worth looking at to give you a sense of what's going on).\n",
    "\n",
    "Note: If you try to open `breast-cancer.data` or `breast-cancer.names` directly, your computer might not know how to handle the file format. To view them, you need to change the file types from .data and .names to .txt — this can be accomplished by simply changing the file name from `breast-cancer.data` to `breast-cancer.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's load the data file into the notebook. All you need to do is put it in the same directory as the notebook and the cell below should locate the appropriate file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data file has been located as breast-cancer.data.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "current_directory = os.listdir()\n",
    "\n",
    "try:\n",
    "  cancer_files = [file for file in current_directory if 'cancer' in file]\n",
    "  data_file = [file for file in cancer_files if 'names' not in file][0]\n",
    "except IndexError:\n",
    "  print('The breast cancer files were not found. Please upload again.')\n",
    "  data_file = None\n",
    "\n",
    "if data_file:\n",
    "  print(f'The data file has been located as {data_file}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**!! If the cell above returned a file that you don't recognize as the correct data file, you must go back to the upload step and ensure you have successfully uploaded your files before proceeding. !!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll try to read the sample into our environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 286 samples in the dataset\n"
     ]
    }
   ],
   "source": [
    "samples = []\n",
    "\n",
    "with open(data_file, 'r') as file:\n",
    "  samples = file.readlines()\n",
    "\n",
    "samples = [sample.split(',') for sample in samples]\n",
    "\n",
    "print(f'There are {len(samples)} samples in the dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now start defining how we want to map our sample values to numeric features that can be used in the decision tree algorithm below. Let's first store our samples in a pandas DataFrame so that it'll be easier to view and work with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>age</th>\n",
       "      <th>menopause</th>\n",
       "      <th>tumor-size</th>\n",
       "      <th>inv-nodes</th>\n",
       "      <th>node-caps</th>\n",
       "      <th>deg-malig</th>\n",
       "      <th>breast</th>\n",
       "      <th>breast-quad</th>\n",
       "      <th>irradiat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no-recurrence-events</td>\n",
       "      <td>30-39</td>\n",
       "      <td>premeno</td>\n",
       "      <td>30-34</td>\n",
       "      <td>0-2</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "      <td>left</td>\n",
       "      <td>left_low</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no-recurrence-events</td>\n",
       "      <td>40-49</td>\n",
       "      <td>premeno</td>\n",
       "      <td>20-24</td>\n",
       "      <td>0-2</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>right</td>\n",
       "      <td>right_up</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no-recurrence-events</td>\n",
       "      <td>40-49</td>\n",
       "      <td>premeno</td>\n",
       "      <td>20-24</td>\n",
       "      <td>0-2</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>left</td>\n",
       "      <td>left_low</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no-recurrence-events</td>\n",
       "      <td>60-69</td>\n",
       "      <td>ge40</td>\n",
       "      <td>15-19</td>\n",
       "      <td>0-2</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>right</td>\n",
       "      <td>left_up</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no-recurrence-events</td>\n",
       "      <td>40-49</td>\n",
       "      <td>premeno</td>\n",
       "      <td>0-4</td>\n",
       "      <td>0-2</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>right</td>\n",
       "      <td>right_low</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>recurrence-events</td>\n",
       "      <td>30-39</td>\n",
       "      <td>premeno</td>\n",
       "      <td>30-34</td>\n",
       "      <td>0-2</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>left</td>\n",
       "      <td>left_up</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>recurrence-events</td>\n",
       "      <td>30-39</td>\n",
       "      <td>premeno</td>\n",
       "      <td>20-24</td>\n",
       "      <td>0-2</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "      <td>left</td>\n",
       "      <td>left_up</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>recurrence-events</td>\n",
       "      <td>60-69</td>\n",
       "      <td>ge40</td>\n",
       "      <td>20-24</td>\n",
       "      <td>0-2</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>right</td>\n",
       "      <td>left_up</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>recurrence-events</td>\n",
       "      <td>40-49</td>\n",
       "      <td>ge40</td>\n",
       "      <td>30-34</td>\n",
       "      <td>3-5</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "      <td>left</td>\n",
       "      <td>left_low</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>recurrence-events</td>\n",
       "      <td>50-59</td>\n",
       "      <td>ge40</td>\n",
       "      <td>30-34</td>\n",
       "      <td>3-5</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "      <td>left</td>\n",
       "      <td>left_low</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>286 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    class    age menopause tumor-size inv-nodes node-caps  \\\n",
       "0    no-recurrence-events  30-39   premeno      30-34       0-2        no   \n",
       "1    no-recurrence-events  40-49   premeno      20-24       0-2        no   \n",
       "2    no-recurrence-events  40-49   premeno      20-24       0-2        no   \n",
       "3    no-recurrence-events  60-69      ge40      15-19       0-2        no   \n",
       "4    no-recurrence-events  40-49   premeno        0-4       0-2        no   \n",
       "..                    ...    ...       ...        ...       ...       ...   \n",
       "281     recurrence-events  30-39   premeno      30-34       0-2        no   \n",
       "282     recurrence-events  30-39   premeno      20-24       0-2        no   \n",
       "283     recurrence-events  60-69      ge40      20-24       0-2        no   \n",
       "284     recurrence-events  40-49      ge40      30-34       3-5        no   \n",
       "285     recurrence-events  50-59      ge40      30-34       3-5        no   \n",
       "\n",
       "    deg-malig breast breast-quad irradiat  \n",
       "0           3   left    left_low       no  \n",
       "1           2  right    right_up       no  \n",
       "2           2   left    left_low       no  \n",
       "3           2  right     left_up       no  \n",
       "4           2  right   right_low       no  \n",
       "..        ...    ...         ...      ...  \n",
       "281         2   left     left_up       no  \n",
       "282         3   left     left_up      yes  \n",
       "283         1  right     left_up       no  \n",
       "284         3   left    left_low       no  \n",
       "285         3   left    left_low       no  \n",
       "\n",
       "[286 rows x 10 columns]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "columns = ['class', 'age', 'menopause', 'tumor-size', 'inv-nodes', \n",
    "           'node-caps', 'deg-malig', 'breast', 'breast-quad', 'irradiat']\n",
    "\n",
    "samples_df = pd.DataFrame(samples, columns=columns)\n",
    "samples_df['irradiat'] = samples_df['irradiat'].str.replace('\\\\n', '')\n",
    "\n",
    "samples_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our DataFrame looks great! Now that we have the raw data stored in an interpretable way, it's good practice to make a copy before trying to encode everything — if something goes wrong, it'll be easy to just come back up here and reset the encoded DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_samples_df = samples_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following few cells, we're going to define the different types of variables that exist in our dataset and make sure we assign the appropriate type of encoding. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, we'll define our binary variables (0,1) and create Python dictionaries to map the string labels to binary integer values. \n",
    "\n",
    "It's also helpful to store all of the columns and dictionaries in two lists so that we can easily reference them later on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cols = ['class', 'breast', 'irradiat']\n",
    "\n",
    "class_map = {'no-recurrence-events': 0, 'recurrence-events': 1}\n",
    "breast_map = {'left': 0, 'right': 1}\n",
    "irrad_map = {'yes': 1, 'no': 0}\n",
    "\n",
    "binary_maps = [class_map, breast_map, irrad_map]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we've defined our ordinal variables (those that have obvious ordered structure). Instead of hard-coding the maps here, it's nice to have a function that can take any number of ordinal columns and instantly create all of the corresponding maps. The code below does that exactly, relying on the integer value of the first number in the range (i.e. '50-65') as the sorting key. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_cols = ['age', 'tumor-size', 'inv-nodes', 'deg-malig']\n",
    "\n",
    "def first_val(x):\n",
    "  return eval(x.split('-')[0].replace(\"'\", ''))\n",
    "  \n",
    "ordinal_maps = {}\n",
    "\n",
    "for col in ordinal_cols:\n",
    "  uniques = sorted(list(encoded_samples_df[col].unique()), key=first_val)\n",
    "  val_map = {}\n",
    "  i = 1\n",
    "\n",
    "  for val in uniques:\n",
    "    val_map[val] = i\n",
    "    i += 1\n",
    "  \n",
    "  ordinal_maps[col] = val_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we have several columns that take n > 2 discrete values. Binary encoding won't work here, so we'll use one-hot encoding. Just like in the cell immediately above, we'll use a function here to take an arbitrary number of columns and encode their unique values as one-hot vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_cols = ['menopause', 'breast-quad', 'node-caps']\n",
    "one_hot_maps = {}\n",
    "\n",
    "def one_hot_map(col, df):\n",
    "  one_hot = {}\n",
    "  unique_vals = list(df[col].unique())\n",
    "  one_hot_vecs = np.identity(len(unique_vals))\n",
    "\n",
    "  for i in range(len(unique_vals)):\n",
    "    one_hot[unique_vals[i]] = one_hot_vecs[i]\n",
    "\n",
    "  return one_hot\n",
    "\n",
    "for col in one_hot_cols:\n",
    "  one_hot_maps[col] = one_hot_map(col, encoded_samples_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all of our encoding maps set up, we'll zip them all up into a master dictionary so that we can easily iterate through them on our `encoded_samples_df` DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_maps = dict(one_hot_maps, **ordinal_maps)\n",
    "for col, val_map in zip(binary_cols, binary_maps):\n",
    "  all_maps[col] = val_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before proceeding, let's double check to make sure you've captured all of the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looks like you successfully created all the maps! Nice work!\n"
     ]
    }
   ],
   "source": [
    "if len(all_maps) != len(columns):\n",
    "  print(\"You're missing a map! Go back and double check that you didn't miss a column.\")\n",
    "else:\n",
    "  print(\"Looks like you successfully created all the maps! Nice work!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now the moment of truth! Let's apply all of our encoding maps on the DataFrame to turn everything into useable features for our decision trees algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>age</th>\n",
       "      <th>menopause</th>\n",
       "      <th>tumor-size</th>\n",
       "      <th>inv-nodes</th>\n",
       "      <th>node-caps</th>\n",
       "      <th>deg-malig</th>\n",
       "      <th>breast</th>\n",
       "      <th>breast-quad</th>\n",
       "      <th>irradiat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>286 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     class  age        menopause  tumor-size  inv-nodes        node-caps  \\\n",
       "0        0    2  [1.0, 0.0, 0.0]           7          1  [1.0, 0.0, 0.0]   \n",
       "1        0    3  [1.0, 0.0, 0.0]           5          1  [1.0, 0.0, 0.0]   \n",
       "2        0    3  [1.0, 0.0, 0.0]           5          1  [1.0, 0.0, 0.0]   \n",
       "3        0    5  [0.0, 1.0, 0.0]           4          1  [1.0, 0.0, 0.0]   \n",
       "4        0    3  [1.0, 0.0, 0.0]           1          1  [1.0, 0.0, 0.0]   \n",
       "..     ...  ...              ...         ...        ...              ...   \n",
       "281      1    2  [1.0, 0.0, 0.0]           7          1  [1.0, 0.0, 0.0]   \n",
       "282      1    2  [1.0, 0.0, 0.0]           5          1  [1.0, 0.0, 0.0]   \n",
       "283      1    5  [0.0, 1.0, 0.0]           5          1  [1.0, 0.0, 0.0]   \n",
       "284      1    3  [0.0, 1.0, 0.0]           7          2  [1.0, 0.0, 0.0]   \n",
       "285      1    4  [0.0, 1.0, 0.0]           7          2  [1.0, 0.0, 0.0]   \n",
       "\n",
       "     deg-malig  breast                     breast-quad  irradiat  \n",
       "0            3       0  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0]         0  \n",
       "1            2       1  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]         0  \n",
       "2            2       0  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0]         0  \n",
       "3            2       1  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]         0  \n",
       "4            2       1  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0]         0  \n",
       "..         ...     ...                             ...       ...  \n",
       "281          2       0  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]         0  \n",
       "282          3       0  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]         1  \n",
       "283          1       1  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]         0  \n",
       "284          3       0  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0]         0  \n",
       "285          3       0  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0]         0  \n",
       "\n",
       "[286 rows x 10 columns]"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in columns:\n",
    "  encoded_samples_df[col] = encoded_samples_df[col].map(all_maps[col])\n",
    "\n",
    "encoded_samples_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double check your `encoded_samples_df` here to make sure everything passes the sniff test! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming it all looks good, the final step is to break up our DataFrame into individual samples, unpack the nested arrays into their constituent values, and concatenate everything together into a final sample vector..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_list = list(encoded_samples_df.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_nested_arrays(vec):\n",
    "  final_vec = np.array([])\n",
    "\n",
    "  for e in vec:\n",
    "    if isinstance(e, int):\n",
    "      e = np.array([e])\n",
    "    final_vec = np.concatenate((final_vec, e))\n",
    "\n",
    "  return final_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_vecs = []\n",
    "for e in sample_list:\n",
    "  final_vecs.append(unpack_nested_arrays(e))\n",
    "\n",
    "final_vecs = np.array(final_vecs, dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! The `final_vecs` variable should now point to a 286x19 numpy.ndarray containing all of our samples. Let's finally move on to the machine learning!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Decision Tree\n",
    "\n",
    "We'll run the decision tree process here again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_cancer_data(split=0.8, shuffle=True, CUTOFF=0, bins = 256):\n",
    "\n",
    "    if shuffle:\n",
    "      np.random.shuffle(final_vecs)\n",
    "    \n",
    "    num_samples = final_vecs.shape[0]\n",
    "    num_train_samples = int(num_samples*split)\n",
    "    \n",
    "    train_data, test_data = final_vecs[:num_train_samples, :], final_vecs[num_train_samples:, :]\n",
    "\n",
    "    X_train = train_data[:, 1:]\n",
    "    y_train = train_data[:, 0]\n",
    "    X_test = test_data[:, 1:]\n",
    "    y_test = test_data[:, 0]\n",
    "\n",
    "    print(X_train.shape)\n",
    "    print(y_train.shape)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the final fit/evaluation code again, but this time using the breast cancer data. You should get somewhere around 0.75 accuracy for the decision tree on this dataset — not 100%, but not too bad for the humble decision tree!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(228, 18)\n",
      "(228,)\n",
      "The decision tree is 65 percent accurate on 228 training data\n",
      "The decision tree is 68 percent accurate on 58 test data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6896551724137931"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = import_cancer_data(split=0.8)\n",
    "\n",
    "tree = DecisionTree(K=3, verbose=False)\n",
    "tree.buildTree(X_train, y_train)\n",
    "\n",
    "tree.homework_evaluate(X_train, y_train, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
